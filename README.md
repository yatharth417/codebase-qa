# Codebase Q&A with Proof

A RAG-based web application that allows you to upload codebases (ZIP or GitHub) and ask questions about them. Get intelligent answers with source attribution - every answer includes file paths and actual code snippets as proof.

## ğŸš€ Live Demo

**[Live App on Railway](https://web-production-9a70b.up.railway.app/)** â† Replace with your actual Railway URL

## âœ¨ Features

- **Multiple Upload Options**: Upload ZIP files or clone from GitHub URLs
- **Smart Code Indexing**: Automatic parsing, chunking, and vector storage
- **Intelligent Q&A**: Ask natural language questions about your codebase
- **Source Attribution**: Every answer includes file paths and code snippets as proof
- **Service Health Monitoring**: Real-time status of LLM, Embeddings, and Vector Database
- **Chat History**: Saves last 10 Q&A pairs in session
- **Multi-Language Support**: Python, JavaScript, TypeScript, Java, C++, Go, Rust, PHP, and more

## ğŸ—ï¸ Tech Stack

- **Frontend**: Streamlit
- **LLM**: Groq (Llama 3.3 70B Versatile)
- **Embeddings**: Google Generative AI (models/gemini-embedding-001)
- **Vector Database**: Chroma (local persistence)
- **Orchestration**: LangChain
- **Text Processing**: RecursiveCharacterTextSplitter

## ğŸ¯ Why These Technologies?

### Groq (LLM)
- âš¡ **Speed**: ~300 tokens/sec inference
- ğŸ’° **Cost**: Free tier with 14,400 requests/day
- ğŸ¯ **Quality**: Llama 3.3 70B excellent for code understanding
- ğŸ”’ **Reliability**: Stable API with good uptime

### Google Generative AI (Embeddings)
- ğŸ¯ **Quality**: 768-dimensional embeddings
- ğŸ’° **Cost**: Free tier with 1500 requests/day
- ğŸ”— **Integration**: Native LangChain support

### Chroma (Vector DB)
- ğŸš€ **Simplicity**: No external service needed
- ğŸ’¾ **Persistence**: Local file storage
- ğŸ”— **Compatibility**: Built-in LangChain integration
- ğŸ’° **Cost**: Completely free

## ğŸ“‹ Requirements

- Python 3.11
- API Keys:
  - [Groq API Key](https://console.groq.com/keys)
  - [Google API Key](https://aistudio.google.com/apikey)

## ğŸ› ï¸ Local Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yatharth417/codebase-qa.git
cd codebase-qa
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure Environment Variables

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_groq_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
```

### 4. Run the Application

```bash
streamlit run app.py
```

The app will open at `http://localhost:8501`

## ğŸ“– How to Use

### Step 1: Check Service Status
Open the app and verify all services show ğŸŸ¢ Connected in the sidebar:
- LLM (Groq)
- Embeddings (Google Gemini)
- Vector DB (Chroma)

### Step 2: Upload & Index Your Codebase

**Option A: Upload ZIP**
1. Navigate to "Upload & Index" tab
2. Choose a ZIP file (max 100MB)
3. Click "Index from ZIP"
4. Wait for indexing to complete

**Option B: GitHub URL**
1. Navigate to "Upload & Index" tab
2. Enter GitHub repository URL
3. Click "Index from GitHub"
4. Wait for cloning and indexing

### Step 3: Ask Questions

1. Go to "Ask Questions" tab
2. Type your question in the chat input
3. View answer with source attribution
4. Expand "View sources" to see actual code snippets

## ğŸ’¬ Example Questions

```
"Where is authentication handled?"
"How do retries work in this codebase?"
"Explain the database connection logic"
"What API endpoints are defined?"
"Show me the error handling implementation"
"How is user data validated?"
"Where are environment variables used?"
```

## ğŸ”§ Configuration

### Limits (configured in `app.py`)

```python
MAX_CODEBASE_SIZE_MB = 100   # Maximum codebase size
MAX_FILES = 50                # Maximum files to index
MAX_FILE_SIZE_MB = 0.5        # Maximum individual file size
```

### Supported File Types

`.py`, `.js`, `.jsx`, `.ts`, `.tsx`, `.java`, `.cpp`, `.c`, `.h`, `.cs`, `.rb`, `.go`, `.rs`, `.php`, `.md`, `.txt`, `.json`, `.yaml`, `.yml`

### Ignored Directories

`node_modules`, `.git`, `__pycache__`, `venv`, `env`, `.next`, `dist`, `build`

## ğŸ† Features Implemented

âœ… ZIP file upload  
âœ… GitHub repository cloning  
âœ… Automatic code indexing with progress tracking  
âœ… RAG-based Q&A with source retrieval  
âœ… Source attribution (file paths + code snippets)  
âœ… Real-time service health monitoring  
âœ… Session-based chat history (last 10 Q&As)  
âœ… Multi-language code support (15+ languages)  
âœ… Error handling for edge cases  
âœ… File size and count limits  

## ğŸ“ Project Structure

```
codebase-qa/
â”œâ”€â”€ app.py                   # Main Streamlit application
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ runtime.txt             # Python version specification
â”œâ”€â”€ Procfile                # Deployment configuration
â”œâ”€â”€ railway.json            # Railway-specific settings
â”œâ”€â”€ .env                    # Environment variables (not committed)
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ chroma_db/             # Vector database storage
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ AI_NOTES.md           # AI development documentation
â”œâ”€â”€ ABOUTME.md            # Developer information
â””â”€â”€ PROMPTS_USED.md       # Development prompts log
```

## ğŸ”’ Security

- âœ… No API keys in code
- âœ… `.env` file excluded from git
- âœ… Input validation for uploads
- âœ… File type restrictions
- âœ… Size limits enforced

## ğŸ§ª Testing

Tested scenarios:
- âœ… ZIP upload with various codebases
- âœ… GitHub cloning with public repositories
- âœ… Q&A with different question types
- âœ… Source snippet display accuracy
- âœ… Service health indicators
- âœ… Error handling for invalid inputs

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io/)
- Powered by [Groq](https://groq.com/)
- Embeddings by [Google Generative AI](https://ai.google.dev/)
- Vector storage by [Chroma](https://www.trychroma.com/)
- Orchestrated with [LangChain](https://www.langchain.com/)

## ğŸ‘¤ Developer

See [ABOUTME.md](ABOUTME.md) for developer information.

## ğŸ“„ License

MIT License

---

**Built as part of a technical assessment - February 2026**
